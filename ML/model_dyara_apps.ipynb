{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model-dyara-apps.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HrPl0WYBClY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPARING DATA"
      ],
      "metadata": {
        "id": "U0HLyGQxDl1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = \"mydata/\"\n",
        "print(os.listdir(source_dir))"
      ],
      "metadata": {
        "id": "1M1kl_VgBSHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_dir = os.listdir(source_dir)\n",
        "print(list_dir)\n",
        "\n",
        "# iterasi untuk menemukan folder gambar\n",
        "index=0\n",
        "for i in range (len(source_dir)):\n",
        "    if source_dir[i]==\"images\":\n",
        "        index=i\n",
        "        break\n",
        "\n",
        "# isi dari image directory\n",
        "index_image = os.listdir(source_dir+list_dir[index])\n",
        "#print(type(imageIndex))\n",
        "head = 10\n",
        "\n",
        "# list kumpulan sampel\n",
        "image_sample = []"
      ],
      "metadata": {
        "id": "4jNhOrxlBSJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_dir = os.listdir(source_dir) \n",
        "# iterasi untuk menemukan folder gambar\n",
        "index=0\n",
        "for i in range (len(list_dir)):\n",
        "    if list_dir[i]==\"images\":\n",
        "        index=i\n",
        "        break\n",
        "\n",
        "# isi dari image directory\n",
        "index_image = os.listdir(list_dir[index])\n",
        "head = 10\n",
        "\n",
        "# list kumpulan sampel\n",
        "image_sample = []\n"
      ],
      "metadata": {
        "id": "QJMKTxknBSMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLEANING DATA"
      ],
      "metadata": {
        "id": "k4kbnaIADqwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = pd.read_csv(source_dir + \"styles.csv\", \n",
        "                 nrows=5000, \n",
        "                 error_bad_lines=False)\n",
        "doc['image'] = doc.apply(lambda x: str(x['id']) + \".jpg\", axis=1)\n",
        "doc.drop(['season', 'year', 'usage', 'productDisplayName'], \n",
        "         axis=1, \n",
        "         inplace=True)\n",
        "print(doc.shape)\n",
        "doc.head(5)"
      ],
      "metadata": {
        "id": "o2oCsmvWBSPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt. figure(figsize=(7,4))\n",
        "for i in range(head):\n",
        "    plt.subplot(2,5,i+1)\n",
        "    plt.imshow(cv2.imread(source_dir + \"images/\" + doc.iloc[i]['image']))\n",
        "    plt.title(doc.iloc[i]['articleType'])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9nYb_B2_LN8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRE-PROCESSING DATA"
      ],
      "metadata": {
        "id": "BQQ1wmlDFPyK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmented = pd.DataFrame({\n",
        "    'filename': doc['image'],\n",
        "    'type'    : doc['articleType']\n",
        "})\n",
        "\n",
        "# total number of entries in the dataframe\n",
        "total_baris = len(data_augmented)\n",
        "print('jumlah baris total: ', total_baris)"
      ],
      "metadata": {
        "id": "lGfejn4NBSUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cloth_type = data_augmented['type'].unique().tolist()\n",
        "total_type = len(cloth_type)\n",
        "print(total_type)\n",
        "print(cloth_type)\n",
        "print(cloth_type[0])\n",
        "print(cloth_type.index(cloth_type[0]))\n",
        "data_augmented['number_types'] = data_augmented['type'].apply(lambda x: cloth_type.index(x) if x in cloth_type else 0)\n",
        "data_augmented.head(10)"
      ],
      "metadata": {
        "id": "7_cusKBLBSWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmented['type'].value_counts()"
      ],
      "metadata": {
        "id": "AKCKkIJoBSZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BUILD MODEL "
      ],
      "metadata": {
        "id": "jvM8S3ivEaOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_data(start,stop):\n",
        "    data_x = []\n",
        "    data_y = []\n",
        "\n",
        "    \n",
        "    for i in range(start, stop): \n",
        "        image_source=source_dir+list_dir[index]+\"/\"+data_augmented.loc[i,'filename']\n",
        "        image = cv2.imread(image_source,cv2.IMREAD_GRAYSCALE)\n",
        "        try:\n",
        "            image_resized = cv2.resize(image, dsize=(28, 28))\n",
        "        except:\n",
        "            print(\"Rejected Image: \"+data_augmented.loc[i,'filename'])\n",
        "            continue\n",
        "        data_x.append(image_resized) \n",
        "        values_y = data_augmented.loc[i,'number_types']\n",
        "        data_y.append(values_y)\n",
        "                \n",
        "    return data_x, data_y"
      ],
      "metadata": {
        "id": "6DTTSEf8BSby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "\n",
        "start = 0\n",
        "stop = int(0.001*total_baris) \n",
        "\n",
        "print(type(X))\n",
        "print(X[0])\n",
        "plt.title(cloth_type[Y[0]])\n",
        "plt.imshow(X[0])"
      ],
      "metadata": {
        "id": "75RZvYjnBwds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X).reshape(-1, 28,28,1)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X = X/255.0\n",
        "Y = Y.reshape(len(X),)"
      ],
      "metadata": {
        "id": "7yDPAXoFBwbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=[]\n",
        "Y=[]\n",
        "start = 0\n",
        "stop = total_baris\n",
        "X,Y=image_data(start,stop)\n",
        "\n",
        "X = np.array(X).reshape(-1, 28,28,1)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X = X/255\n",
        "\n",
        "Y = Y.reshape(len(X),)\n",
        "\n",
        "print('Image Data Shape: ',X.shape)\n",
        "print('Label Data Shape: ',Y.shape)"
      ],
      "metadata": {
        "id": "y8kwMN0bBwYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 500)\n",
        "print('Train Image Data Shape: ',X_train.shape)\n",
        "print('Train Label Data Shape: ',Y_train.shape)\n",
        "print('Test Image Data Shape: ',X_test.shape)\n",
        "print('Test Label Data Shape: ',Y_test.shape)"
      ],
      "metadata": {
        "id": "5Y24eZHHBwWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_validate, Y_train, Y_validate = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 500)\n",
        "print('Train Image Data Shape: ',X_train.shape)\n",
        "print('Train Label Data Shape: ',Y_train.shape)\n",
        "print('Validation Image Data Shape: ',X_validate.shape)\n",
        "print('Validation Label Data Shape: ',Y_validate.shape)"
      ],
      "metadata": {
        "id": "RQaz7ffvBwTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "Gy4ufJrtBwQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), \n",
        "                     activation='relu', \n",
        "                     input_shape=(28,28,1)))\n",
        "    model.add(Conv2D(64, (3, 3), \n",
        "                     activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, \n",
        "                    activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(cloth_type), \n",
        "                    activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', \n",
        "                  optimizer='Adam', \n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model=create_model()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "fE9SsDVYBwNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "bKQPeG9jmQqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, \n",
        "                    Y_train, \n",
        "                    batch_size=128, \n",
        "                    epochs=50, \n",
        "                    verbose=1, \n",
        "                    validation_data=(X_validate, Y_validate))"
      ],
      "metadata": {
        "id": "lD2U9HWFl8Gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model.history.history['acc'],color='g')\n",
        "plt.plot(model.history.history['loss'],color='r')\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['accuracy', 'loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FJ8RIFBkl-LN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model"
      ],
      "metadata": {
        "id": "YNKQNUrCmbXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('f_recommend.h5')"
      ],
      "metadata": {
        "id": "qZOyThSRmI9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "tflite_model = tf.keras.models.load_model('f_recommend.h5')\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(tflite_model)\n",
        "tflite_save = converter.convert()\n",
        "open(\"mdel.tflite\", \"wb\").write(tflite_save)"
      ],
      "metadata": {
        "id": "ogIsCQW6mLev"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}